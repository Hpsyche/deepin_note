## package

* 基本复用模块单元

  以首字母大写来表明可被包外代码访问

* 代码的package可以和所在的目录不一致

* 同一目录里的Go代码的package要保持一致

首先，在series包下有：

```go
package series

func GetFibonacciSeries(n int) []int {
	a := []int{1, 1}
	for i := 2; i < n; i++ {
		a = append(a, a[i-1]+a[i-2])
	}
	return a
}
```

在client包下有：

```go
package client

import (
	"fmt"
	"main/ch13/series"
	"testing"
)

//通过import，引入series包下的函数
func TestPackage(t *testing.T) {
	fmt.Println(series.GetFibonacciSeries(5))
}
```

当GetFibonacciSeries修改为getFibonacciSeries时，即函数首字母变成小写，报错undefined。

* 通过go get来获取远程依赖

  go get -u 强制从网络更新远程依赖（去http://，和.git）

* 注意代码在Github上的组织形式，以适应go get

  直接以代码路径开始，不要有src

## init方法

* 在main被执行前，所有依赖的package的init方法都会被执行；
* 不同包的init函数按照包导入的依赖关系决定执行顺序
* 每个包可以有多个init函数
* 包的每个源文件也可以有多个init函数，这点比较特殊

## 依赖管理

### Go未解决的依赖问题

* 同一环境下，不同项目使用同一包的不同版本
* 无法管理对包的特定版本的依赖

### vendor路径

随着go1.5 release版本的发布，vendor目录被添加到除了gopath和goroot之外的依赖目录查找解决方案。在go1.6之前，你需要手动设置环境变量。

查找依赖包路径的解决方案如下：

* 当前包下的vendor目录
* 向上级目录查找，直到找到src下的vendor目录
* 在gopath下面查找依赖包
* 在goroot目录下查找

### 常用的依赖管理工具

* godep
* glide
* dep

## Thread vs. Groutine

* 创建时默认的stack大小

  JDK5以后Java Thread Stack默认为1M

  Groutine的Stack初始化大小为2K

* 和KSE（Kernal Space Entity）的对应关系

  Java Thread是1:1

  Groutine是M:N

![](/media/hpsyche/_dde_data/note/go/go基础/pict/4-1.png)

![](/media/hpsyche/_dde_data/note/go/go基础/pict/4-2.png)

* 如果一个协程占用时间特别长，队列里其他的协程就被延迟很久了？

  go启动时，会有一个用于计数的守护线程 ，用于记录Processor完成的协程数量，如果在一段时间内，发现数量不发生变化，就会在协程任务栈就插入一个标记，协程运行时遇到非内联函数时，就会看到这个标记，就把自己中断下来，插到等候协程队列的队尾，再切换回别的协程，进行进一步的运行。

* 提高并发能力的机制：当某个协程被系统中断了，如IO，为了提高整体的并发，Processor会把自己提到一个可以使用的线程当中，继续执行它挂载的协程，当这个等待IO的协程完成后，其会加入到某一个Processor的等待队列中。

  当一个协程被中断时，其在寄存器中的运行状态也会保存到协程对象中，当协程再次获得运行机会时，这些运行状态会再次写入寄存器中，继续运行。

```go
func TestGroutine(t *testing.T) {
	for i := 0; i < 100; i++ {
		// go func(i int) {
		// 	fmt.Println(i)
		// }(i)
		go func() {
			fmt.Println(i)
		}()
	}
	time.Sleep(time.Microsecond * 50)
}
//第一种写法为正确的写法
//output:
3
2
0
6
4
5
9
1
...
//乱序输出，说明协程发挥了其作用。
//第二种写法为错误的写法
//output:
4
11
11
11
11
11
11
11
//原因：i为全局变量，各个协程之间共享，所有各个协程拿到的i变量不是独自拥有的私有变量。
```

## 共享内存并发机制

```go
func TestShareMem(t *testing.T) {
	counter := 0
	for i := 0; i < 10000; i++ {
		go func() {
			counter += 1
		}()
	}
	time.Sleep(time.Microsecond * 100)
	fmt.Println(counter)
}
```

发现counter小于10000，原因：多线程（协程）并发问题，参考JVM i++；

解决方案，添加Mutex信号量！

````go
func TestShareMem(t *testing.T) {
	var mut sync.Mutex
	counter := 0
	for i := 0; i < 10000; i++ {
		go func() {
			defer func() {
				mut.Unlock()
			}()
			mut.Lock()
			counter += 1
		}()
	}
	time.Sleep(time.Microsecond * 100)
	fmt.Println(counter)
}
````

## WaitGroup

相当于Thrad.join()，即需要等待wg里所有协程完成时才继续

如下

```go
func TestWaitGroup(t *testing.T) {
	var mut sync.Mutex
	counter := 0
	for i := 0; i < 10000; i++ {
		go func() {
			defer func() {
				mut.Unlock()
			}()
			mut.Lock()
			counter++
		}()
	}
	fmt.Println(counter)
}
```

发现输出小于10000，原因是在fmt.Println(counter)时，counter还未++完毕，故数据小于10000

我们添加waitgroup，如下：

```go
func TestWaitGroup(t *testing.T) {
	var mut sync.Mutex
	var wg sync.WaitGroup
	counter := 0
	for i := 0; i < 10000; i++ {
		wg.Add(1)
		go func() {
			defer func() {
				mut.Unlock()
			}()
			mut.Lock()
			counter++
			wg.Done()
		}()
	}
	wg.Wait()
	fmt.Println(counter)
}
//output:
10000
```

## CSP

首先介绍下Actor模式，Actor模式流程如下：

![](/media/hpsyche/_dde_data/note/go/极客时间/pict/4-3.png)

### CSP vs. Actor

* 和Actor的直接通讯不同，CSP模式则是通过Channel进行通讯的，更松耦合一些。
* Go中channel是有容量限制并且独立于处理Groutine，而如Erlang，Actor模式中的mailbox容量是无限的，接收进程也总是被动地处理消息。

![](/media/hpsyche/_dde_data/note/go/极客时间/pict/4-4.png)

```go
func Serivce() string {
	time.Sleep(time.Microsecond * 50)
	return "Done"
}
func OtherService() {
	fmt.Println("2")
	time.Sleep(time.Microsecond * 100)
	fmt.Println("3")
}
func TestCsp(t *testing.T) {
	fmt.Println(Serivce())
	OtherService()
}
//output：
Done
2
3
```

串行化执行。

异步操作：

```go
func Serivce() string {
	time.Sleep(time.Millisecond * 50)
	return "Done"
}
func OtherService() {
	fmt.Println("2")
	time.Sleep(time.Millisecond * 100)
	fmt.Println("3")
}
func AsynService() chan string {
	channel := make(chan string)
	var ret string
	go func() {
		fmt.Println("4")
		ret = Serivce()
		channel <- ret
		fmt.Println("5")
	}()
	return channel
}
func TestAsyn(t *testing.T) {
	res := AsynService()
	OtherService()
	fmt.Println(<-res)
	time.Sleep(time.Second * 1)
}
//output:
2
4
3
Done
5
```

原因，2和4的顺序不一定，看开辟新协程后，CPU先调度的协程方法（主线程or新协程），2\4之后，由于channel为阻塞式（直到有人receive后才解除阻塞），所以即使Serivce执行时间较短，也无济于事，故0.1s后，执行3，<-时，返回channel结果，即Done，最后执行下一行的5；

接着看下带buffered的channel（容量设为1）

```go
func Serivce() string {
	time.Sleep(time.Millisecond * 50)
	return "Done"
}
func OtherService() {
	fmt.Println("2")
	time.Sleep(time.Millisecond * 100)
	fmt.Println("3")
}
func AsynService() chan string {
	channel := make(chan string,1)
	var ret string
	go func() {
		fmt.Println("4")
		ret = Serivce()
		channel <- ret
		fmt.Println("5")
	}()
	return channel
}
func TestAsyn(t *testing.T) {
	res := AsynService()
	OtherService()
	fmt.Println(<-res)
	time.Sleep(time.Second * 1)
}
//output:
2
4
5
3
Done
```

2\4同上，由于Serivce执行时间较短，return结果被放到了缓冲区里面，接着输出了5，待OtherService执行完毕输出3，最后输出返回结果Done。

## 多路选择和超时控制

### select

#### 多渠道的选择

```go
select{
    case ret:=<-retCh1:
    t.Logf("result %s",ret)
    case ret:=<-retCh2:
    t.Logf("result %s",ret)
	default:
    t.Error("No one returned")
}
```

演示：

```go
func Serivce() string {
	time.Sleep(time.Millisecond * 500)
	return "Done"
}

func AsynService() chan string {
	channel := make(chan string, 1)
	var res string
	go func() {
		res = Serivce()
		channel <- res
	}()
	return channel
}

func SerivceSecond() string {
	time.Sleep(time.Millisecond * 50)
	return "SecondDone"
}

func AsynServiceSecond() chan string {
	channel := make(chan string, 1)
	var res string
	go func() {
		res = SerivceSecond()
		channel <- res
	}()
	return channel
}
func TestSelect(t *testing.T) {
	select {
	case ret := <-AsynService():
		fmt.Println(ret)
	case ret := <-AsynServiceSecond():
		fmt.Println(ret)
	}
}
//output:
SecondDone
```

由于SerivceSecond先退出，select到了second channel的数据。

#### 超时控制

```go
select{
	case ret:=<-retCh:
    t.Logf("result %s",ret)
    case <-time.After(time.Second*1):
    t.Error("time out")
}
```

演示：

```go
func Serivce() string {
	time.Sleep(time.Millisecond * 500)
	return "Done"
}

func AsynService() chan string {
	channel := make(chan string, 1)
	var res string
	go func() {
		res = Serivce()
		channel <- res
	}()
	return channel
}

func SerivceSecond() string {
	time.Sleep(time.Millisecond * 500)
	return "SecondDone"
}

func AsynServiceSecond() chan string {
	channel := make(chan string, 1)
	var res string
	go func() {
		res = SerivceSecond()
		channel <- res
	}()
	return channel
}

func TestSelect(t *testing.T) {
	select {
	case ret := <-AsynService():
		fmt.Println(ret)
	case ret := <-AsynServiceSecond():
		fmt.Println(ret)
	case <-time.After(time.Millisecond * 100):
		fmt.Println("time out")
	}
}
//output:
time out
```

service运行时间都修改为500，同时设置超时时间100，超过100，输出time out。

## channel的关闭

* 向关闭的channel发送数据，会导致panic
* v,ok<-ch;ok为bool值，true表示正常接受，false表示通道关闭
* 所有的channel接收者都会在channel关闭时，立即从阻塞等待中返回且上述ok值为false。这个广播机制常被利用，进行向多个订阅者同时发送信号。如：退出信号。

```go
func dataProducer(ch chan int, wg *sync.WaitGroup) {
	go func() {
		for i := 0; i < 10; i++ {
			ch <- i
		}
		wg.Done()
	}()
}

func dataConsumer(ch chan int, wg *sync.WaitGroup) {
	go func() {
		for i := 0; i < 10; i++ {
			data := <-ch
			fmt.Println(data)
		}
		wg.Done()
	}()
}

func TestChannel(t *testing.T) {
	ch := make(chan int)
	var wg sync.WaitGroup
	wg.Add(2)
	dataProducer(ch, &wg)
	dataConsumer(ch, &wg)
	wg.Wait()
}
//output:
0
1
2
3
4
5
6
7
8
9
```

若此时我们添加一个退出机制，怎么实现呢？

* 约定一个值，如消费者收到-1即退出，但这样有一定的缺点，如果有多个reveive，需要add多个-1，这样子不科学，耦合性较高；
* 使用go中channel提供的关闭机制

```go
func dataProducer(ch chan int, wg *sync.WaitGroup) {
	go func() {
		for i := 0; i < 10; i++ {
			ch <- i
		}
		close(ch)
		wg.Done()
	}()
}

func dataConsumer(ch chan int, wg *sync.WaitGroup) {
	go func() {
		for {
			if data, ok := <-ch; ok {
				fmt.Println(data)
			} else {
				break
			}
		}
		wg.Done()
	}()
}

func TestChannel(t *testing.T) {
	ch := make(chan int)
	var wg sync.WaitGroup
	wg.Add(3)
	dataProducer(ch, &wg)
	dataConsumer(ch, &wg)
	dataConsumer(ch, &wg)
	wg.Wait()
}
```

将消费端改为data, ok := <-ch; 后，对ok进行判断，true取数据，false关闭，至此for循环不再需要手动写环迅10次，降低了代码耦合度，同时，我们开启多个dataConsumer，也实现了“单生产者-多消费者”的模型。

注意：如果消费者不加以判断，是否ok，在关闭了channel后，消费者再去接收通道数据均为0。

## 任务的取消

```go
func TestCancel(t *testing.T) {
	var wg sync.WaitGroup
	cancelChan := make(chan struct{}, 1)
	for i := 0; i < 5; i++ {
		wg.Add(1)
		go func(i int, canCh chan struct{}) {
			for {
				if isCancelled(canCh) {
					break
				}
				time.Sleep(time.Millisecond * 10)
			}
			fmt.Println(i, "is Cancelled")
			wg.Done()
		}(i, cancelChan)
	}
	cancel_1(cancelChan)
	wg.Wait()
}

func cancel_1(cancelChan chan struct{}) {
	cancelChan <- struct{}{}
}

func isCancelled(canCh chan struct{}) bool {
	select {
	case <-canCh:
		return true
	default:
		return false
	}
}
//output:
2 is Cancelled
```

发现只cancel了一条协程，原因也很显而易见，我们只cancelChan在缓冲区放入了一个数据，只有一条协程收到了数据，故只退出了一条。

```go
func TestCancel(t *testing.T) {
	var wg sync.WaitGroup
	cancelChan := make(chan struct{}, 1)
	for i := 0; i < 5; i++ {
		wg.Add(1)
		go func(i int, canCh chan struct{}) {
			for {
				if isCancelled(canCh) {
					break
				}
				time.Sleep(time.Millisecond * 10)
			}
			fmt.Println(i, "is Cancelled")
			wg.Done()
		}(i, cancelChan)
	}
	cancel_2(cancelChan)
	wg.Wait()
}

func cancel_2(cancelChan chan struct{}) {
	close(cancelChan)
}

func isCancelled(canCh chan struct{}) bool {
	select {
	case <-canCh:
		return true
	default:
		return false
	}
}
//output:
0 is Cancelled
2 is Cancelled
4 is Cancelled
3 is Cancelled
1 is Cancelled
```

## Context

* 根Context：通过Context.Background()创建
* 子Context：context.WithCancel(parentContext)创建
  * ctx,cancel:=context.WithCancal(context.Background)
* 当前Context被取消时，基于他的子context都会被取消
* 接收取消通知<-ctx.Done()

```go
func TestCancel(t *testing.T) {
	var wg sync.WaitGroup
	ctx, cancel := context.WithCancel(context.Background())
	for i := 0; i < 5; i++ {
		wg.Add(1)
		go func(i int, cxt context.Context) {
			for {
				if isCancelled(cxt) {
					break
				}
				time.Sleep(time.Millisecond * 5)
			}
			fmt.Println(i, "is Cancelled")
			wg.Done()
		}(i, ctx)
	}
	cancel()
	wg.Wait()
}
//output:
4 is Cancelled
1 is Cancelled
2 is Cancelled
3 is Cancelled
0 is Cancelled
```

