## Goroutine

### 什么是Goroutine

go使用Goroutine来实现并发。

Goroutine被认为是轻量级的线程。与线程相比，创建Goroutine的成本很小，它就是一段代码，一个函数入口，以及在堆上为其分配的一个堆栈（初始大小为4KB，会随着程序的执行自动增长删除）。因此它非常廉价，Go应用程序可以并发运行数千个Goroutines。

Goroutine在线程上的优势：

* 与线程相比，Goroutine非常便宜，它们只是堆栈大小的几个KB，堆栈可以根据应用程序的需要增长和收缩，而在线程的情况下，堆栈大小必须指定并且是固定的；
* Goroutine被多路复用到较少的OS线程。在一个程序可能只有一个线程与数千个Goroutines。如果线程中的任何Goroutine都表示等待用户输入，则会创建另一个OS线程，剩下的Goroutine被转移到新的OS线程。所有这些都由运行时进行处理，我们作为程序员从这些复杂的细节中抽象出来，并得到了一个与并发工作相关的干净的API；
* 当使用Goroutine访问共享内存时，通过设计的通道可以防止竞态条件发生。通道可以被认为是Goroutine通信的管道。

### 主Goroutine

封装main函数的goroutine称为主goroutine。

主goroutine所做的事情并不是执行main函数那么简单。它首先要做的是：设定每一个goroutine所能申请的栈空间的最大尺寸。在32位的计算机系统中此最大尺寸为250MB，而在64位的计算机系统中此尺寸为1GB。如果有某个goroutine的栈空间尺寸大于这个限制，那么运行时系统就会引发一个栈溢出的运行时恐慌。随后，这个go程序的运行也会终止。

此后，主goroutine会进行一系列的初始化工作，设计的工作内容大致如下：

1. 创建一个特殊的defer语句，用于在主goroutine退出时做必要的善后处理，因为主goroutine也可能非正常的结束；

2. 启动专用于在后台清扫内存垃圾的goroutine，并设置GC的标识；

3. 执行main包中的init函数；

4. 执行main函数；

   执行完main函数后，它还会检查主goroutine是否引发了运行时恐慌，并进行必要的处理，最后主goroutine会结束自己以及当前进程的运行。

### Goroutine规则

* 当新的Goroutine开始时，Goroutine调用立即返回。与函数不同，go不等待goroutine执行结束。当goroutine调用并且goroutine的任何返回值被忽略之后，go立即执行到下一行代码；
* main的goroutine应该为其他goroutine执行，即如果main的goroutine终止了，程序将被终止，而其他的goroutine将不会运行。

## Go线程模型

操作系统根据资源访问权限的不同，体系架构分为用户空间和内核空间：内核空间主要操作访问CPU资源、IO资源、内存资源等硬件资源，为上层应用程序提供最基本的基础资源，用户空间是上层应用的固定活动空间，用户空间不可以直接访问资源，必须通过“系统调用”，“库函数”和“Shell脚本”来调用内核空间提供的资源。

我们使用的计算机语言，可以狭义地认为是一种“软件”，它们中的“线程”，往往是用户态的线程，和操作系统本身内核态的线程（KSE），还是有区别的。

线程的实现模型主要为3个，分别是：用户线程模型、内核线程模型和两级线程模型。

### 内核线程模型

用户线程和KSE是1对1关系，大部分编程语言的线程库（如linux的pthread、Java的java.lang.Thread、C++11的std::thread等等）都是对操作系统的线程（内核级线程）的一层封装， 创建出来的每个线程与一个不同的KSE静态关联，因此其调度完全由操作系统调度器来做。显然，在需要使用大量线程的情况下对模型对OS性能的影响很大。

![](/media/hpsyche/_dde_data/note/go/千峰/pict/2-1.png)

每个线程由内核调度器独立调度，如果一个线程阻塞也不影响其他的线程。

优点：在多核处理器的硬件支持下，其支持了真正的并行，当一个线程被阻塞后，允许另一个线程继续执行，所以并发能力强。

缺点：每创建一个用户级线程都需要一个内核级线程与其对应，开销较大，影响程序性能。

### 用户级线程模型

用户级线程与KSE是多对1关系（M：1），线程的创建、销毁及多个线程之间的协调等操作都是由用户自己实现的线程库来负责，对OS内核透明，一个进程中所有创建的线程都与同一个KSE在运行时动态关联。现在有许多语言实现的协程基本上都属于这种方式。这种实现方法相比内核级线程可以做的很轻量级，对系统资源会小很多。

但该模型有个致命的缺点，即如果某个用户线程调用阻塞式系统调用（如用阻塞方法read网络IO），那么一旦KSE因阻塞被内核调度出CPU的话，剩下的所有对应的用户线程都会变成阻塞状态（整个进程挂起）。

所以！！！这些语言的协程库会把自己一些阻塞的操作重新封装成完全的非阻塞形式，然后在以前要阻塞的点上，主动让出自己，并通过某种方式通知或唤醒其他待执行的用户线程在该KSE上运行，从而避免了内核调度器由于KSE阻塞而做上下文切换，这样整个进程而不会被阻塞了。

![](/media/hpsyche/_dde_data/note/go/千峰/pict/2-2.png)

### 两级线程模型

用户模型和KSE是多对多的关系（M：N），这种实现综合了前两种模型的优点，为一个进程中创建多个KSE，并且线程可以与不同的KSE在运行时进行动态关联，当某个KSE由于其上工作的线程的阻塞操作而被内核调度出CPU时，当前与其关联的其余用户线程可以重新与其他KSE建立联系。

这种动态关联机制较为复杂，也需要用户自己去实现，算是缺点之一。**Go语言中的并发就是使用此实现方式。**此模型有时也被称为混合线程模型：即**用户调度器实现用户线程到KSE的调度，内核调度器实现KSE到CPU上的调度。**

![](/media/hpsyche/_dde_data/note/go/千峰/pict/2-3.png)

## Go并发调度：G-P-M模型

### 调度器是如何工作的

Go语言中支撑整个scheduler实现的主要有4个重要结构，分别是M、G、P、Sched，前三个定义在runtime.h中，Sched定义在proc.c中。

* Sched结构就是调度器，它维护有存储M和G队列以及调度器的一些状态信息等；

* M结构是Machine，系统线程，它是由操作系统管理的，goroutine就是跑在M上面的，M是一个很大的结构，里面维护小对象的cache、当前执行的goroutine、随机数发生器等信息；

* P结构是Processor，处理器，它主要用来执行goroutine，维护了一个goroutine队列，即runqueue。Processor是从我们N：1调度到M：N调度的重要部分；

* G是Goroutine实现的核心结构，它包含了栈、指令指针，以及其他对调度goroutine很重要的信息，例如其阻塞的channel等。

  > Processor的数量在启动时被设置为环境变量GOMAXPROCS的值，或者通过运行时调用函数GOMAXPROCS()进行设置，Processor数量固定意味着任意时刻只有GOMAXPROCS个线程在运行Go代码。

在单核处理器的情况下，所有goroutine运行在同一个M系统线程中，每一个M系统线程维护一个Processor，任何时刻，一个Processor中只有一个goroutine，其他goroutine在runqueue中等待。一个goroutine运行完自己的时间片后，让出上下文，回到runqueue中。多核处理器的场景下，为了运行goroutines，每个M系统线程会持有一个Processor。

![](/media/hpsyche/_dde_data/note/go/千峰/pict/2-4.png)

在正常情况下，scheduler会按照上面的流程进行调度，但是线程会发生阻塞的情况，以下是goroutine对线程阻塞等的情况。

### 线程阻塞

当正在运行的goroutine阻塞的时候，例如进行系统调用，会创建一个系统线程（M），当前的M线程放弃了它的Processor，P转到新的线程中去运行。

![](/media/hpsyche/_dde_data/note/go/千峰/pict/2-5.png)

原先M0作为一个内核线程，正在执行G0协程，而在P中，有三个协程在等待；此时G0阻塞了，此时创建M1内核线程，并将P与M1进行关联，则队列中等待的三个协程则会挂到M1中去，而M0下的G0仍然在阻塞操作中。

 ### runqueue

当其中一个Processor中的runqueue为空，没有goroutine可以调度。它会从另外一个上下文偷取一半的goroutine。

![](/media/hpsyche/_dde_data/note/go/千峰/pict/2-6.png)

好像M、G就可以实现线程模型了，为什么还需要P？

其实Go在1.0的时候，在并发模型实现中，并没有P的概念，Go语言的调度器直接把G分配到适当的M上面去，但是带来了很多问题：

* G在不同M上并发运行时，都需要向系统申请资源（堆栈内存），但是由于资源是全局的，就会由于资源竞争造成很多系统性能的损耗。
* 让P管理G对象，M想要运行G时，就必须先去绑定一个P，然后才能去运行这个P管理的G，这样在P对象中可以优先申请资源，当G想要资源时，可以先向P申请，如果不够用，再向全局申请；
* 由于P解耦了M和G，假如在M上运行了一个阻塞式的G，那么其余和M关联的G，也可以随着P迁移到其他的活跃的M上去运行，让G总能找到M并运行起来，从而提高系统的并发能力。
* Go通过GPM模型实现了一套用户态的并发调度系统，可以自己管理和调度自己的并发任务，Go语言原生支持并发，**自己实现的调度器负责把并发任务分配到不同的内核线程上去运行，然后内核调度器接管内核线程在CPU上的执行和调度**。